import {
    create
} from 'venom-bot'
import * as dotenv from 'dotenv'
import {
    Configuration,
    OpenAIApi
} from "openai"

dotenv.config()

create({
        session: 'chat-gpt',
        multidevice: true
    })
    .then((client) => start(client))
    .catch((erro) => {
        console.log(erro);
    });

const configuration = new Configuration({
    organization: process.env.ORGANIZATION_ID,
    apiKey: process.env.OPENAI_KEY
});

const getDavinciResponse = async (clientText) => {
    const options = {
        model: "text-davinci-003", // Modelo GPT a ser usado
        prompt: clientText, // Texto enviado pelo usuÃ¡rio
        temperature: 1, // NÃ­vel de variaÃ§Ã£o das respostas geradas, 1 Ã© o mÃ¡ximo
        max_tokens: 4000 // Quantidade de tokens (palavras) a serem retornadas pelo bot, 4000 Ã© o mÃ¡ximo
    }

    try {
        const response = await openai.createCompletion(options)
        let botResponse = ""
        response.data.choices.forEach(({
            text
        }) => {
            botResponse += text
        })
        return `Chat GPT ğŸ¤–\n\n ${botResponse.trim()}`
    } catch (e) {
        return `âŒ OpenAI Response Error: ${e.response.data.error.message}`
    }
}

const commands = (client, message) => {
    const iaCommands = {
        davinci3: "/bot",
    }

    let firstWord = message.text.substring(0, message.text.indexOf(" "));

    switch (firstWord) {
        case iaCommands.davinci3:
            const question = message.text.substring(message.text.indexOf(" "));
            getDavinciResponse(question).then((response) => {
                client.sendText(message.from === process.env.BOT_NUMBER ? message.to : message.from, response)
            })
            break;
    }
}

async function start(client) {
    client.onAnyMessage((message) => commands(client, message));
}